{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel_process_NIH import build_raw_data, snorkel_process,loop_labing\n",
    "import os \n",
    "from bertrnn_preprocess_NIH import bertrnn_process\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12544/12544 [00:07<00:00, 1766.36it/s]\n"
     ]
    }
   ],
   "source": [
    "allfile, allsent=build_raw_data('/home/COVID_NIH/all_data/alldata_all_abstract.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "allsent['newpid']=range(len(allsent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('/home/text_download/keylist.txt', \"r\") as f:\n",
    "    alist =f.read().splitlines()\n",
    "    for line in alist:\n",
    "        keylist=line.split(',')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "valuelist = []\n",
    "with open('/home/text_download/valuelist.txt', \"r\") as f:\n",
    "    alist =f.read().splitlines()\n",
    "    for line in alist:\n",
    "        valuelist.append(line.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "allweaklabf=loop_labing(keylist,valuelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81008/81008 [01:37<00:00, 829.01it/s]\n"
     ]
    }
   ],
   "source": [
    "trainsent,trainlabel,valsent,vallabel,keylist,report=snorkel_process (keylist,allsent,allweaklabf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>keyword_icubation_timeab</th>\n",
       "      <td>0</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.001790</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyword_no symptom spreadingab</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.002518</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.000198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyword_environmental materialab</th>\n",
       "      <td>2</td>\n",
       "      <td>[2]</td>\n",
       "      <td>0.009925</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyword_bio wasteab</th>\n",
       "      <td>3</td>\n",
       "      <td>[3]</td>\n",
       "      <td>0.008357</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.000210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyword_environemntab</th>\n",
       "      <td>4</td>\n",
       "      <td>[4]</td>\n",
       "      <td>0.007123</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>0.000358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyword_action controlab</th>\n",
       "      <td>5</td>\n",
       "      <td>[5]</td>\n",
       "      <td>0.001555</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  j Polarity  Coverage  Overlaps  Conflicts\n",
       "keyword_icubation_timeab          0      [0]  0.001790  0.000160   0.000160\n",
       "keyword_no symptom spreadingab    1      [1]  0.002518  0.000198   0.000198\n",
       "keyword_environmental materialab  2      [2]  0.009925  0.000272   0.000272\n",
       "keyword_bio wasteab               3      [3]  0.008357  0.000210   0.000210\n",
       "keyword_environemntab             4      [4]  0.007123  0.000358   0.000358\n",
       "keyword_action controlab          5      [5]  0.001555  0.000099   0.000099"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "startw=np.count_nonzero(trainlabel== 1, axis=0)\n",
    "defualt=np.max(startw)\n",
    "squarer = lambda t: defualt/t\n",
    "trainweight=np.array([squarer(xi) for xi in startw])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "testsent=allsent.sent.values\n",
    "testlabel=allsent.newpid.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "args={\"modelname1\":'bert-base-uncased',\n",
    "      \"modelname2\":'scibert_scivocab_uncased',\n",
    "      \"num_labels\":len(trainlabel[0]),\n",
    "      \"hidden_size\":256,\n",
    "      \"num_layers\":1,\n",
    "      \"bidirectional\":1,\n",
    "      \"dropout\":0.2,\n",
    "      \"batch_size\":10,\n",
    "      \"epochs\":100,\n",
    "      \"lr\":0.001,\n",
    "      \"seed\": 1,\n",
    "      \"early_stop_times\":1,\n",
    "      \"science\":True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1984/1984 [00:00<00:00, 2284.00it/s]\n",
      "100%|██████████| 496/496 [00:00<00:00, 2343.66it/s]\n",
      "100%|██████████| 81008/81008 [00:29<00:00, 2736.71it/s]\n",
      "100%|██████████| 1984/1984 [00:00<00:00, 2264.86it/s]\n",
      "100%|██████████| 496/496 [00:00<00:00, 2327.85it/s]\n",
      "100%|██████████| 81008/81008 [00:29<00:00, 2704.63it/s]\n",
      "100%|██████████| 81008/81008 [00:00<00:00, 1187047.54it/s]\n",
      "100%|██████████| 1984/1984 [00:00<00:00, 20680.70it/s]\n",
      "100%|██████████| 496/496 [00:00<00:00, 20291.39it/s]\n",
      "100%|██████████| 81008/81008 [00:03<00:00, 21176.94it/s]\n",
      "100%|██████████| 1984/1984 [00:00<00:00, 20876.92it/s]\n",
      "100%|██████████| 496/496 [00:00<00:00, 20849.62it/s]\n",
      "100%|██████████| 81008/81008 [00:03<00:00, 21150.57it/s]\n",
      "100%|██████████| 1984/1984 [00:00<00:00, 2326.45it/s]\n",
      "100%|██████████| 496/496 [00:00<00:00, 2347.22it/s]\n",
      "100%|██████████| 81008/81008 [00:34<00:00, 2355.43it/s]\n",
      "100%|██████████| 1984/1984 [00:00<00:00, 2363.99it/s]\n",
      "100%|██████████| 496/496 [00:00<00:00, 2450.08it/s]\n",
      "100%|██████████| 81008/81008 [00:34<00:00, 2343.20it/s]\n"
     ]
    }
   ],
   "source": [
    "norloder,sciloder=bertrnn_process(args,trainsent,valsent,testsent,trainlabel,vallabel,testlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from transformers import BertModel\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import label_ranking_loss\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "from transformers import BertModel, BertConfig, AdamW\n",
    "from tqdm import tqdm\n",
    "\n",
    "class bert_rnn(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(bert_rnn, self).__init__()\n",
    "        self.args = args\n",
    "        self.emb1=BertModel.from_pretrained(self.args['modelname1'],num_labels = self.args['num_labels'],output_attentions = False,output_hidden_states = False)#.cuda(3)\n",
    "        self.emb1_size=self.emb1.config.hidden_size\n",
    "        if self.args['science']==True:\n",
    "            self.emb2=BertModel.from_pretrained(self.args['modelname2'],num_labels = self.args['num_labels'],output_attentions = False,output_hidden_states = False)#.cuda(3)\n",
    "            self.emb2_size=self.emb2.config.hidden_size\n",
    "            self.emb_size=self.emb1_size+self.emb2_size\n",
    "        else:\n",
    "            self.emb_size=self.emb1_size\n",
    "        self.lin1 = nn.Linear(self.emb_size, self.args['hidden_size'])\n",
    "        if self.args['bidirectional']>1:\n",
    "            bidirectional=2\n",
    "            dif=True\n",
    "        else:\n",
    "            bidirectional=1\n",
    "            dif=False\n",
    "        self.rnn=nn.LSTM(input_size=self.args['hidden_size'], hidden_size =self.args['hidden_size'], num_layers =self.args['num_layers'],batch_first= True,dropout=self.args['dropout'],bidirectional=dif)\n",
    "        self.lin2 = nn.Linear(self.args['hidden_size'], self.args['num_labels'])\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "    def forward(self,data1,mask1,target,data2=None,mask2=None):\n",
    "        if self.args['science']==True:\n",
    "            emb1=self.emb1(data1,attention_mask=mask1)\n",
    "            last_hidden_states1 = emb1[0]\n",
    "            emb2=self.emb2(data2,attention_mask=mask2)\n",
    "            last_hidden_states2 = emb2[0]\n",
    "            last_hidden_states = torch.cat((last_hidden_states1, last_hidden_states2), 2)\n",
    "            last_hidden_states = self.lin1(last_hidden_states)\n",
    "        else:\n",
    "            emb1=self.emb1(data1)\n",
    "            last_hidden_states1 = emb1[0]\n",
    "            last_hidden_states = self.lin1(last_hidden_states1)\n",
    "        output, _ = self.rnn(last_hidden_states)#,# (self.h0, self.c0))\n",
    "        output=torch.mean(output, 1)\n",
    "        out = self.lin2(output)\n",
    "        out=self.sigmoid(out)\n",
    "        return out,target\n",
    "    def parameters (self):\n",
    "        if self.args['science']==True:\n",
    "            params=list(self.emb1.parameters())+list(self.emb2.parameters())+list(self.rnn.parameters())+list(self.lin1.parameters())+list(self.lin2.parameters())\n",
    "        else:\n",
    "            params=list(self.emb1.parameters())+list(self.rnn.parameters())+list(self.lin1.parameters())+list(self.lin2.parameters())\n",
    "        return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_(model,loss,optimizer,dataloaders1,epoch,dataloaders2=None):\n",
    "    allloss=[]\n",
    "    allbatch=[]\n",
    "    print('Train')\n",
    "    if args['science']==True:\n",
    "        for batch_idx, batch in tqdm(enumerate(zip(dataloaders1, dataloaders2))):\n",
    "            data1, mask1, target1 = batch[0]\n",
    "            data2, mask2, target2 = batch[1]\n",
    "            target1 = Variable(target1).cuda()\n",
    "            data1 = Variable(data1).cuda()\n",
    "            mask1=Variable(mask1).cuda()\n",
    "            target2 = Variable(target2).cuda()\n",
    "            data2 = Variable(data2).cuda()\n",
    "            mask2=Variable(mask2).cuda()\n",
    "            optimizer.zero_grad()\n",
    "            out,target = model.forward(data1,mask1,target1,data2,mask2)\n",
    "            lossall = loss(out,target.float())            \n",
    "            lossall = torch.sum(lossall)\n",
    "            lossall.backward()\n",
    "            optimizer.step()\n",
    "            loss1=lossall.item()\n",
    "            allloss.append(loss1)\n",
    "            allbatch.append(batch_idx*epoch)\n",
    "    else:\n",
    "        for batch_idx, batch in tqdm(enumerate(dataloaders1)):\n",
    "            data1, mask1, target1 = batch\n",
    "            target1 = Variable(target1).cuda(3)\n",
    "            data1 = Variable(data1).cuda(3)\n",
    "            mask1=Variable(mask1).cuda(3)\n",
    "            optimizer.zero_grad()\n",
    "            out,target = model.forward(data1,mask1,target1)\n",
    "            lossall = loss(out,target.float())            \n",
    "            lossall = torch.sum(lossall)\n",
    "            lossall.backward()\n",
    "            optimizer.step()\n",
    "            allloss.append(lossall)\n",
    "            allbatch.append(batch_idx*epoch)\n",
    "    return allloss, allbatch\n",
    "def val_(model,dataloaders1,dataloaders2=None):\n",
    "    allout=[]\n",
    "    alltarget=[]\n",
    "    print('Validation')\n",
    "    if args['science']==True:\n",
    "        for batch_idx, batch in tqdm(enumerate(zip(dataloaders1, dataloaders2))):\n",
    "            data1, mask1, target1 = batch[0]\n",
    "            data2, mask2, target2 = batch[1]\n",
    "            target1 = Variable(target1).cuda()\n",
    "            data1 = Variable(data1).cuda()\n",
    "            mask1=Variable(mask1).cuda()\n",
    "            target2 = Variable(target2).cuda()\n",
    "            data2 = Variable(data2).cuda()\n",
    "            mask2=Variable(mask2).cuda()\n",
    "            with torch.no_grad(): \n",
    "                out,target = model.forward(data1,mask1,target1,data2,mask2)\n",
    "            out=out.cpu().detach().numpy()\n",
    "            target=target.to('cpu').numpy().astype(int)\n",
    "            \n",
    "            allout.append(list(out))\n",
    "            alltarget.append(list(target))\n",
    "    else:\n",
    "        for batch_idx, batch in tqdm(enumerate(dataloaders1)):\n",
    "            data1, mask1, target1 = batch\n",
    "            target1 = Variable(target1).cuda()\n",
    "            data1 = Variable(data1).cuda()\n",
    "            mask1=Variable(mask1).cuda()\n",
    "            with torch.no_grad(): \n",
    "                out,target = model.forward(data1,mask1,target1)\n",
    "            out=out.cpu().detach().numpy()\n",
    "            target=target.to('cpu').numpy().astype(int)\n",
    "            \n",
    "            allout.append(list(out))\n",
    "            alltarget.append(list(target))\n",
    "    return allout,alltarget\n",
    "def test_(model,dataloaders1,dataloaders2=None):\n",
    "    allout=[]\n",
    "    alltarget=[]\n",
    "    print('test')\n",
    "    if args['science']==True:\n",
    "        for batch_idx, batch in tqdm(enumerate(zip(dataloaders1, dataloaders2))):\n",
    "            data1, mask1, target1 = batch[0]\n",
    "            data2, mask2, target2 = batch[1]\n",
    "            target1 = Variable(target1).cuda()\n",
    "            data1 = Variable(data1).cuda()\n",
    "            mask1=Variable(mask1).cuda()\n",
    "            target2 = Variable(target2).cuda()\n",
    "            data2 = Variable(data2).cuda()\n",
    "            mask2=Variable(mask2).cuda()\n",
    "            with torch.no_grad(): \n",
    "                out,target = model.forward(data1,mask1,target1,data2,mask2)\n",
    "            out=out.cpu().detach().numpy()\n",
    "            target=target.to('cpu').numpy().astype(int)\n",
    "            \n",
    "            allout.append(out)\n",
    "            alltarget.append(target)\n",
    "    else:\n",
    "        for batch_idx, batch in tqdm(enumerate(dataloaders1)):\n",
    "            data1, mask1, target1 = batch\n",
    "            target1 = Variable(target1).cuda()\n",
    "            data1 = Variable(data1).cuda()\n",
    "            mask1=Variable(mask1).cuda()\n",
    "            with torch.no_grad(): \n",
    "                out,target = model.forward(data1,mask1,target1)\n",
    "            out=out.cpu().detach().numpy()\n",
    "            target=target.to('cpu').numpy().astype(int)\n",
    "            \n",
    "            allout.append(out)\n",
    "            alltarget.append(target)\n",
    "    return allout,alltarget\n",
    "def result(result):\n",
    "    alllist=[]\n",
    "    for i in result:\n",
    "        for j in i:\n",
    "            alllist.append(j)\n",
    "    return alllist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "199it [01:23,  2.39it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:06,  7.24it/s]\n",
      "1it [00:00,  8.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- new best lrl0.06814516129032258\n",
      "test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8101it [18:35,  7.26it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "199it [01:11,  2.79it/s]\n",
      "1it [00:00,  7.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:06,  7.27it/s]\n",
      "1it [00:00,  7.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- new best lrl0.018548387096774192\n",
      "test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8101it [18:15,  7.40it/s]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "199it [01:10,  2.81it/s]\n",
      "1it [00:00,  7.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [00:06,  7.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "- early stopping 3 epochs without improvement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\" )\n",
    "torch.cuda.set_device(11)\n",
    "model= bert_rnn(args)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model=nn.DataParallel(model, device_ids=[11,12,13,14])\n",
    "model.to(device)\n",
    "params=model.parameters()\n",
    "optimizer = AdamW(params,lr = 2e-5, eps = 1e-8 )\n",
    "#trainweight=torch.tensor(trainweight).cuda()\n",
    "loss = nn.MSELoss()\n",
    "alloss=[]\n",
    "allbatch=[]\n",
    "dev_lrl=1\n",
    "vallrl=[]\n",
    "testpred=[]\n",
    "testpid=[]\n",
    "current_early_stop_times=0\n",
    "for epoch in range(1, args['epochs'] + 1):\n",
    "    epochloss, epochbatch=train_(model,loss,optimizer,norloder[0],epoch,dataloaders2=sciloder[0])\n",
    "    alloss.append(epochloss)\n",
    "    allbatch.append(epochbatch)\n",
    "    allout,alltarget=val_(model,norloder[1],sciloder[1])\n",
    "    allout1=result(allout)\n",
    "    alltarget1=result(alltarget)\n",
    "    epochlrl=label_ranking_loss(alltarget1,allout1)\n",
    "    vallrl.append(epochlrl)\n",
    "    if epochlrl < dev_lrl:\n",
    "        print(\"- new best lrl{}\".format(epochlrl))\n",
    "        allout,alltarget=test_(model,norloder[2],sciloder[2])\n",
    "        allout=result(allout)\n",
    "        alltarget=result(alltarget)\n",
    "        allpd=pd.DataFrame(allout,columns=keylist)\n",
    "        allpd['newpid']=alltarget\n",
    "        allpd.to_csv('Bert_NIH_task1_LSTM.csv')\n",
    "        dev_lrl = epochlrl\n",
    "        current_early_stop_times = 0\n",
    "    else:\n",
    "        current_early_stop_times += 1\n",
    "        print(current_early_stop_times)\n",
    "    if current_early_stop_times >= args['early_stop_times'] :\n",
    "        break;\n",
    "print (\"- early stopping {} epochs without improvement\".format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allpd=pd.DataFrame(allout,columns=keylist)\n",
    "allpd['newpid']=alltarget\n",
    "allpd.to_csv('Bert_NIH_Task1_LSTM.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(next(iter(sciloder[2]))[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result(alltarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
