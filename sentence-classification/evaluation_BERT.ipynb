{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from snorkel_process import snorkel_process\n",
    "import warnings\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import scispacy\n",
    "from scispacy.umls_linking import UmlsEntityLinker\n",
    "warnings.filterwarnings('ignore')\n",
    "from snorkel_process_NIH import build_raw_data\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import transformers\n",
    "transformers.tokenization_utils.logger.setLevel(logging.ERROR)\n",
    "transformers.configuration_utils.logger.setLevel(logging.ERROR)\n",
    "transformers.modeling_utils.logger.setLevel(logging.ERROR)\n",
    "from bert_score import score,scorer\n",
    "\n",
    "from sklearn.linear_model import SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3269/3269 [00:02<00:00, 1461.70it/s]\n"
     ]
    }
   ],
   "source": [
    "allfile, allsent=build_raw_data('/home/text_download/inhibitor_NIH_ab.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "allsent['newpid']=range(len(allsent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_sci_lg')\n",
    "linker = UmlsEntityLinker(resolve_abbreviations=True)\n",
    "nlp.add_pipe(linker)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/text_download/keylist.txt', \"r\") as f:\n",
    "    alist =f.read().splitlines()\n",
    "    for line in alist:\n",
    "        keylist=line.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "valuelist = []\n",
    "with open('/home/text_download/valuelist.txt', \"r\") as f:\n",
    "    alist =f.read().splitlines()\n",
    "    for line in alist:\n",
    "        valuelist.append(line.split(','))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matcher (nlp, terms):\n",
    "    patterns = [nlp(text) for text in terms]\n",
    "    matcher = PhraseMatcher(nlp.vocab)\n",
    "    matcher.add(\"TerminologyList\", None, *patterns)\n",
    "    return matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reportfu(dataframe, pidlist,matcher,nlp):\n",
    "    allmatchnu=[]\n",
    "    for doc in dataframe.sent.values:\n",
    "        doc=nlp(str(doc))\n",
    "        matches = matcher(doc)\n",
    "        allmatch=[]\n",
    "        for match_id, start, end in matches:\n",
    "            rule_id = nlp.vocab.strings[match_id]\n",
    "            span = doc[start : end]\n",
    "            allmatch.append(span)\n",
    "        matchnu=len(allmatch)\n",
    "        allmatchnu.append(matchnu)\n",
    "    return allmatchnu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=pd.read_csv('Bert_NIH_task4_Q1_LSTM.csv')\n",
    "file=file.drop(columns=['Unnamed: 0'])\n",
    "file=file.merge(allsent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [1:06:40<00:00, 500.11s/it]\n"
     ]
    }
   ],
   "source": [
    "alllabel1=pd.DataFrame()\n",
    "for i in tqdm(range(len(keylist))) :\n",
    "    newdata=file[['newpid',keylist[i],'sent','pid']].sort_values(by=keylist[i],ascending =False)\n",
    "    matchers=matcher(nlp, valuelist[i])\n",
    "    pidlist=newdata.newpid.values  \n",
    "    allmatchnu=reportfu(newdata, pidlist,matchers,nlp)\n",
    "    allmatchnu1=np.where(np.array(allmatchnu) >0, 1, 0)\n",
    "    newdata['label']=allmatchnu1\n",
    "    newdata=newdata.rename(columns={keylist[i]:'predict_prob'})\n",
    "    newdata['category']=[keylist[i]]*len(newdata)\n",
    "    alllabel1=pd.concat([newdata,alllabel1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold=pd.read_csv('./inhibitor_NIH_ab_COVID.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "refg=alllabel1[alllabel1.pid.isin(gold.pid.values)]\n",
    "refg=refg.sort_values(['predict_prob', 'label'], ascending=[False, True])\n",
    "refg=refg[(refg.predict_prob>=0.7)&(refg.label==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "refg=refg[['newpid','sent','category']].drop_duplicates()\n",
    "cand=alllabel1[['newpid','sent','category']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorylist=list(cand.category.drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [11:36<00:00, 87.01s/it] \n"
     ]
    }
   ],
   "source": [
    "allframe=pd.DataFrame()\n",
    "for i in tqdm(range(len(categorylist))):\n",
    "    refg1=refg[refg.category==categorylist[i]]\n",
    "    refgsent=list(refg1.sent.values)\n",
    "    refgsentn=len(refgsent)\n",
    "    cand1=cand[cand.category==categorylist[i]]\n",
    "    candsent=list(cand1.sent.values)\n",
    "    candsentn=len(candsent)\n",
    "    if refgsentn==0:\n",
    "        sentence=candsent\n",
    "        score1=[0]*candsentn\n",
    "        category=[categorylist[i]]*candsentn\n",
    "        tempframe=pd.DataFrame(sentence,columns=['sent'])\n",
    "        tempframe['score']=score1\n",
    "        tempframe['category']=category\n",
    "        allframe=pd.concat([allframe,tempframe])\n",
    "    else :\n",
    "        testrefsent=[]\n",
    "        testcandsent=[]\n",
    "        for j in range(len(candsent)):\n",
    "            for k in range(len(refgsent)):\n",
    "                testrefsent.append(refgsent[k])\n",
    "                testcandsent.append(candsent[j])\n",
    "        P, R, F1 = score(testcandsent, testrefsent, lang='en-sci', verbose=False)\n",
    "        sentence=testcandsent\n",
    "        score1=list(F1.numpy())\n",
    "        tempframe=pd.DataFrame(sentence,columns=['sent'])\n",
    "        tempframe['score']=score1\n",
    "        tempframe=tempframe.groupby('sent').mean().reset_index()\n",
    "        category=[categorylist[i]]*len(tempframe)\n",
    "        tempframe['category']=category\n",
    "        allframe=pd.concat([allframe,tempframe])\n",
    "        \n",
    "allframe=allframe.sort_values(by=['category','score'],ascending=False).drop_duplicates()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "allframe1=allframe.merge(alllabel1)\n",
    "allframe1=allframe1[['newpid','pid','category','score','predict_prob','label']]\n",
    "allframe1=allframe1.sort_values(['score','label','predict_prob' ], ascending=[False,False, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "goldframe=pd.DataFrame()\n",
    "for i in categorylist:\n",
    "    tempframe1=allframe1[allframe1.category==i].head(n=50)    \n",
    "    tempframe1=tempframe1[tempframe1.label==1]\n",
    "    tempframe1['real_label']=[1]*len(tempframe1)\n",
    "    tempframe2=allframe1[allframe1.category==i].tail(n=50)    \n",
    "    tempframe2=tempframe2[tempframe2.label==0]\n",
    "    tempframe2['real_label']=[0]*len(tempframe2)\n",
    "    tempframe=pd.concat([tempframe1,tempframe2])\n",
    "    goldframe=pd.concat([goldframe,tempframe])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "allframe2=pd.DataFrame()\n",
    "for i in categorylist:\n",
    "    tempframe=allframe1[allframe1.category==i]\n",
    "    goldframe1=goldframe[goldframe.category==i]\n",
    "    allx=tempframe[['score','predict_prob','label']].values\n",
    "    goldx=goldframe1[['score','predict_prob','label']].values\n",
    "    goldy=goldframe1[['real_label']].values\n",
    "    fit=SGDRegressor()\n",
    "    fit.fit(X=goldx ,y=goldy)\n",
    "    ally=fit.predict(allx)\n",
    "    tempframe['newscore']=ally\n",
    "    tempframe=tempframe.sort_values(by='newscore',ascending=False)\n",
    "    allframe2=pd.concat([tempframe,allframe2])\n",
    "allframe2=allframe2[['newpid','pid','category','newscore']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "alllabel12=alllabel1[['pid','newpid','category','sent']]\n",
    "alllabel12=alllabel12.merge(allframe2).sort_values(by=['category','newscore'],ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "alllabel12.to_csv('ALLRanking_TASK4_Q1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "alllabel13=pd.DataFrame()\n",
    "for i in categorylist:\n",
    "    tempframe=alllabel12[alllabel12.category==i][0:1000]\n",
    "    alllabel13=pd.concat([tempframe,alllabel13])\n",
    "alllabel13.to_csv('ALLRanking_TASK4_Q1_TOP_1000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allfile.to_csv('ALLRanking')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
